# -*- coding: utf-8 -*-
"""flux onnx 4 bit

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CRcQo9wBIHhv3r8OfWKJ4OpCmjx9JMLd
"""



!pip install git+https://github.com/huggingface/diffusers.git@main # add support for `FluxKontextPipeline`
!pip install transformers>=4.53.1 # add support for hqq quantized model in diffusers pipeline
!pip install -U bitsandbytes
!pip install -U hqq

# 2. Import and load the quantized pipeline
import torch
from diffusers import FluxKontextPipeline
from diffusers.utils import load_image

device = "cuda" if torch.cuda.is_available() else "cpu"

pipe = FluxKontextPipeline.from_pretrained(
    "HighCWu/FLUX.1-Kontext-dev-bnb-hqq-4bit",
    torch_dtype=torch.bfloat16
)
pipe.to(device)

# Confirm it's working
print("âœ… 4-bit Quantized FLUX.1 Kontext loaded!")

from huggingface_hub import HfApi, login
from huggingface_hub.utils import HfHubHTTPError

token = "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"

try:
    login(token=token)  # Attempt login
    api = HfApi(token=token)
    user = api.whoami()
    print("âœ… Token is valid.")
    print(f"Logged in as: {user['name']}")
except HfHubHTTPError as e:
    print("âŒ Invalid or expired token.")
    print("Error:", e)

!pip install ultralytics

from ultralytics import YOLO

# load the segmentation-ready YOLOv8 model
yolo = YOLO('yolov8s-seg.pt')  # or your custom weights
print("âœ… YOLOv8â€‘seg loaded.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Cell 5: Autoâ€‘prompt generator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_flux_prompt(label, bbox, img_w, img_h, include_pos=True):
    if include_pos:
        x1, y1, x2, y2 = bbox
        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
        vert = "top"    if cy < img_h/2 else "bottom"
        hori = "left"   if cx < img_w/2 else "right"
        pos = f" from the {vert}-{hori} corner"
    else:
        pos = ""
    return f"Remove the {label}{pos}"

from PIL import Image
import numpy as np

def detect_and_remove(img_path, mode='all', selections=None):
    img = Image.open(img_path).convert('RGB')
    original_size = img.size
    target_size = 512
    img_resized = img.resize((target_size, target_size))

    if mode == 'all':
        # Fixed prompt (no YOLO detection)
        prompt = "Remove everything from the room including furniture like bed, sofa, couch, table, lamp, plants, curtains."

    elif mode == 'select':
        # YOLO detection for selected objects
        res = yolo.predict(source=np.array(img_resized), imgsz=512, device='cuda', save=False)[0]
        labels = [res.names[int(c)] for c in res.boxes.cls]

        # Extended room-relevant YOLO-detectable classes
        valid_room_items = [
            'sofa', 'couch', 'chair', 'table', 'bed', 'lamp', 'tv', 'cabinet', 'desk',
            'stool', 'curtain', 'carpet', 'painting', 'mirror', 'shelf',
            'pillow', 'cushion', 'potted plant', 'plant', 'vase', 'rug', 'bowl', 'book'
        ]

        detected_labels = sorted(set(label.lower().rstrip('s') for label in labels))
        targets = [item for item in (selections or []) if item in detected_labels and item in valid_room_items]

        if len(targets) > 1:
            prompt = "Remove " + ", ".join(targets[:-1]) + " and " + targets[-1] + " from the room"
        elif len(targets) == 1:
            prompt = f"Remove {targets[0]} from the room"
        else:
            prompt = "Don't remove anything"

    else:
        raise ValueError("âŒ mode must be 'all' or 'select'")

    print("ğŸ§  Auto-prompt:", prompt)

    result = pipe(
        prompt=prompt,
        image=img_resized,
        guidance_scale=7.0,
        num_inference_steps=35
    ).images[0]

    result_upscaled = result.resize(original_size)
    result_upscaled.save("output_flux_result.png")
    print("âœ… Done: Saved as output_flux_result.png")

    return result_upscaled

from google.colab import files
from PIL import Image
import numpy as np

# Upload image
uploaded = files.upload()
uploaded_filename = list(uploaded.keys())[0]
img = Image.open(uploaded_filename).convert('RGB')
print("ğŸ“ Image size:", img.size)

# Ask mode
print("\nğŸ“Œ Choose mode:\n1ï¸âƒ£ - Remove all furniture\n2ï¸âƒ£ - Select items to remove")
mode = input("Enter 1 or 2: ").strip()

# Resize image for YOLO
img_resized = img.resize((512, 512))

# Run YOLO detection
res = yolo.predict(source=np.array(img_resized), imgsz=512, device='cuda', save=False)[0]
all_labels = [res.names[int(c)] for c in res.boxes.cls]
detected_labels = sorted(set(all_labels))

# Define main function
def detect_and_remove(img_path, mode='all', selections=None):
    img = Image.open(img_path).convert('RGB')
    original_size = img.size
    target_size = 512
    img_resized = img.resize((target_size, target_size))

    if mode == 'all':
        prompt = "Remove everything from the room including all furniture like bed, sofa, couch, table, lamp, chairs, curtains, decor items, etc., except the walls and carpet."
    elif mode == 'select':
        targets = selections or []
        if len(targets) > 1:
            prompt = "Remove " + ", ".join(targets[:-1]) + " and " + targets[-1] + " from the room"
        elif len(targets) == 1:
            prompt = f"Remove {targets[0]} from the room"
        else:
            prompt = "Don't remove anything"
    else:
        raise ValueError("âŒ mode must be 'all' or 'select'")

    print("ğŸ§  Auto-prompt:", prompt)

    # Inpaint using already loaded quantized FLUX pipeline
    result = pipe(
        prompt=prompt,
        image=img_resized,
        guidance_scale=7.0,
        num_inference_steps=35
    ).images[0]

    result_upscaled = result.resize(original_size)
    result_upscaled.save("output_flux_result.png")
    print("âœ… Done: Saved as output_flux_result.png")
    return result_upscaled

# Mode logic
if mode == "1":
    out = detect_and_remove(uploaded_filename, mode="all")
    display(out)
    files.download("output_flux_result.png")

elif mode == "2":
    print("\nğŸ” Detected in Image:", detected_labels)

    # Get user selections
    user_input = input("âœï¸ Enter items to remove (comma-separated): ")
    user_items = [item.strip().lower().rstrip('s') for item in user_input.replace(" and ", ",").split(",")]

    # Match selections with detected items
    detected_cleaned = {x.lower().rstrip('s'): x for x in detected_labels}
    selected_items = []

    for item in user_items:
        if item in detected_cleaned:
            selected_items.append(detected_cleaned[item])

    if selected_items:
        print("ğŸ¯ Selected:", selected_items)
        out = detect_and_remove(uploaded_filename, mode="select", selections=selected_items)
        display(out)
        files.download("output_flux_result.png")
    else:
        print("âŒ No valid items selected.")
else:
    print("âš ï¸ Invalid selection. Please enter 1 or 2.")

from google.colab import files
from PIL import Image
import numpy as np

# Upload image
uploaded = files.upload()
uploaded_filename = list(uploaded.keys())[0]
img = Image.open(uploaded_filename).convert('RGB')
print("ğŸ“ Image size:", img.size)

# Ask mode
print("\nğŸ“Œ Choose mode:\n1ï¸âƒ£ - Remove all furniture\n2ï¸âƒ£ - Select items to remove")
mode = input("Enter 1 or 2: ").strip()

# Resize image for YOLO
img_resized = img.resize((512, 512))

# Run YOLO detection
res = yolo.predict(source=np.array(img_resized), imgsz=512, device='cuda', save=False)[0]
all_labels = [res.names[int(c)] for c in res.boxes.cls]
detected_labels = sorted(set(all_labels))

# Define main function
def detect_and_remove(img_path, mode='all', selections=None):
    img = Image.open(img_path).convert('RGB')
    original_size = img.size
    target_size = 512
    img_resized = img.resize((target_size, target_size))

    if mode == 'all':
        prompt = "Remove everything from the room including all furniture like bed, sofa, couch, table, lamp, chairs, curtains, decor items, etc., except the walls and carpet."
    elif mode == 'select':
        targets = selections or []
        if len(targets) > 1:
            prompt = "Remove " + ", ".join(targets[:-1]) + " and " + targets[-1] + " from the room"
        elif len(targets) == 1:
            prompt = f"Remove {targets[0]} from the room"
        else:
            prompt = "Don't remove anything"
    else:
        raise ValueError("âŒ mode must be 'all' or 'select'")

    print("ğŸ§  Auto-prompt:", prompt)

    # Inpaint using already loaded quantized FLUX pipeline
    result = pipe(
        prompt=prompt,
        image=img_resized,
        guidance_scale=7.0,
        num_inference_steps=35
    ).images[0]

    result_upscaled = result.resize(original_size)
    result_upscaled.save("output_flux_result.png")
    print("âœ… Done: Saved as output_flux_result.png")
    return result_upscaled

# Mode logic
if mode == "1":
    out = detect_and_remove(uploaded_filename, mode="all")
    display(out)
    files.download("output_flux_result.png")

elif mode == "2":
    print("\nğŸ” Detected in Image:", detected_labels)

    # Get user selections
    user_input = input("âœï¸ Enter items to remove (comma-separated): ")
    user_items = [item.strip().lower().rstrip('s') for item in user_input.replace(" and ", ",").split(",")]

    # Match selections with detected items
    detected_cleaned = {x.lower().rstrip('s'): x for x in detected_labels}
    selected_items = []

    for item in user_items:
        if item in detected_cleaned:
            selected_items.append(detected_cleaned[item])

    if selected_items:
        print("ğŸ¯ Selected:", selected_items)
        out = detect_and_remove(uploaded_filename, mode="select", selections=selected_items)
        display(out)
        files.download("output_flux_result.png")
    else:
        print("âŒ No valid items selected.")
else:
    print("âš ï¸ Invalid selection. Please enter 1 or 2.")

import gradio as gr
from PIL import Image
import numpy as np

# Assumed: `pipe` and `yolo` are already loaded in notebook as per your code

valid_room_items = [
    'sofa', 'couch', 'chair', 'table', 'bed', 'lamp', 'tv', 'cabinet', 'desk',
    'stool', 'curtain', 'carpet', 'painting', 'mirror', 'shelf',
    'pillow', 'cushion', 'potted plant', 'plant', 'vase', 'rug', 'bowl', 'book'
]

def run_yolo(image):
    img_resized = image.resize((512, 512))
    result = yolo.predict(source=np.array(img_resized), imgsz=512, device='cuda', save=False)[0]
    all_labels = [result.names[int(c)] for c in result.boxes.cls]
    detected_labels = sorted(set(label.lower().rstrip('s') for label in all_labels))
    filtered = [item for item in detected_labels if item in valid_room_items]
    return list(set(filtered))

def generate_prompt(mode, selections=None):
    if mode == 'all':
        return "Remove everything from the room including all furniture like bed, sofa, couch, table, lamp, chairs, curtains, decor items, etc., except the walls and carpet."
    elif mode == 'select':
        if not selections:
            return "Don't remove anything"
        elif len(selections) == 1:
            return f"Remove {selections[0]} from the room"
        else:
            return "Remove " + ", ".join(selections[:-1]) + " and " + selections[-1] + " from the room"
    else:
        raise ValueError("Invalid mode")

def process(image, mode, selections):
    original_size = image.size
    img_resized = image.resize((512, 512))

    prompt = generate_prompt(mode, selections)
    print("ğŸ§  Auto-prompt:", prompt)

    result = pipe(
        prompt=prompt,
        image=img_resized,
        guidance_scale=7.0,
        num_inference_steps=35
    ).images[0]

    result_upscaled = result.resize(original_size)
    return result_upscaled

# Gradio UI
def interface_main(image, mode):
    if mode == 'select':
        detected = run_yolo(image)
        return gr.update(visible=True, choices=detected, value=[]), gr.update(visible=True)
    else:
        return gr.update(visible=False), gr.update(visible=True)

with gr.Blocks() as demo:
    gr.Markdown("## ğŸ›‹ï¸ Room Object Remover with FLUX + YOLO")
    with gr.Row():
        with gr.Column():
            image_input = gr.Image(label="Upload Room Image", type="pil")
            mode = gr.Radio(choices=["all", "select"], label="Choose Mode", value="all")
            detected_items = gr.CheckboxGroup(choices=[], label="Select objects to remove", visible=False)
            run_button = gr.Button("Run")
        with gr.Column():
            output_image = gr.Image(label="Output Image", interactive=False)

    # Trigger on mode change
    mode.change(fn=interface_main, inputs=[image_input, mode], outputs=[detected_items, run_button])

    # Main run button
    run_button.click(fn=process, inputs=[image_input, mode, detected_items], outputs=[output_image])

demo.launch()

from google.colab import files
from PIL import Image
import numpy as np

# Upload image
uploaded = files.upload()
uploaded_filename = list(uploaded.keys())[0]
img = Image.open(uploaded_filename).convert('RGB')
print("ğŸ“ Image size:", img.size)

# Ask mode
print("\nğŸ“Œ Choose mode:\n1ï¸âƒ£ - Remove all furniture\n2ï¸âƒ£ - Select items to remove")
mode = input("Enter 1 or 2: ").strip()

# Resize image for YOLO
img_resized = img.resize((512, 512))

# Run YOLO detection
res = yolo.predict(source=np.array(img_resized), imgsz=512, device='cuda', save=False)[0]
all_labels = [res.names[int(c)] for c in res.boxes.cls]
detected_labels = sorted(set(all_labels))

# Define main function
def detect_and_remove(img_path, mode='all', selections=None):
    img = Image.open(img_path).convert('RGB')
    original_size = img.size
    target_size = 512
    img_resized = img.resize((target_size, target_size))

    if mode == 'all':
        prompt = "Remove everything from the room including all furniture like bed, sofa, couch, table, lamp, chairs, curtains, decor items, etc., except the walls and carpet."
    elif mode == 'select':
        targets = selections or []
        if len(targets) > 1:
            prompt = "Remove " + ", ".join(targets[:-1]) + " and " + targets[-1] + " from the room"
        elif len(targets) == 1:
            prompt = f"Remove {targets[0]} from the room"
        else:
            prompt = "Don't remove anything"
    else:
        raise ValueError("âŒ mode must be 'all' or 'select'")

    print("ğŸ§  Auto-prompt:", prompt)

    # Inpaint using already loaded quantized FLUX pipeline
    result = pipe(
        prompt=prompt,
        image=img_resized,
        guidance_scale=7.0,
        num_inference_steps=35
    ).images[0]

    result_upscaled = result.resize(original_size)
    result_upscaled.save("output_flux_result.png")
    print("âœ… Done: Saved as output_flux_result.png")
    return result_upscaled

# Mode logic
if mode == "1":
    out = detect_and_remove(uploaded_filename, mode="all")
    display(out)
    files.download("output_flux_result.png")

elif mode == "2":
    print("\nğŸ” Detected in Image:", detected_labels)

    # Get user selections
    user_input = input("âœï¸ Enter items to remove (comma-separated): ")
    user_items = [item.strip().lower().rstrip('s') for item in user_input.replace(" and ", ",").split(",")]

    # Match selections with detected items
    detected_cleaned = {x.lower().rstrip('s'): x for x in detected_labels}
    selected_items = []

    for item in user_items:
        if item in detected_cleaned:
            selected_items.append(detected_cleaned[item])

    if selected_items:
        print("ğŸ¯ Selected:", selected_items)
        out = detect_and_remove(uploaded_filename, mode="select", selections=selected_items)
        display(out)
        files.download("output_flux_result.png")
    else:
        print("âŒ No valid items selected.")
else:
    print("âš ï¸ Invalid selection. Please enter 1 or 2.")

